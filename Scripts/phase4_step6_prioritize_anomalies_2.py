# -*- coding: utf-8 -*-
"""phase4_step6_prioritize_anomalies_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MMJf2dpDnqxbsLeex1nTd_V95NTWB32z
"""

import pandas as pd
import numpy as np
import traceback
import os
import datetime

# --- Configuration ---
input_directory = r"C:\Users\anith\Downloads"
engineered_features_timestamp = "20250428_205234"
prep_timestamp = "20250428_230602"
baseline_results_timestamp = "20250428_230602"
ae_results_timestamp = "20250428_211422"
engineered_features_filename = f"sap_engineered_features__{engineered_features_timestamp}.csv"
baseline_results_filename = f"phase3_step4a_baseline_results_{baseline_results_timestamp}.csv"
ae_results_filename = f"phase4_step5_autoencoder_gpu_results_{ae_results_timestamp}.csv"
input_engineered_path = os.path.join(input_directory, engineered_features_filename)
input_baseline_results_path = os.path.join(input_directory, baseline_results_filename)
input_ae_results_path = os.path.join(input_directory, ae_results_filename)
output_directory = r"C:\Users\anith\Downloads"

# --- Prioritization Parameters ---
IF_SCORE_PERC_HIGH = 1.0; LOF_SCORE_PERC_HIGH = 1.0; AE_MSE_PERC_HIGH = 99.0
USER_DEV_ABS_PERC = 98.0; ACCT_DEV_ABS_PERC = 98.0
HIGH_VALUE_ABS_PERC = 99.5; LOW_VALUE_ABS_THRESHOLD = 1.00
NUM_ANOMALIES_TO_OUTPUT = 500

# --- Output File Naming ---
SCRIPT_NAME = "prioritize_anomalies"; PHASE_NUMBER = 4; STEP_PRIORITIZE = "6"
TIMESTAMP = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
prioritized_list_filename = f"phase{PHASE_NUMBER}_step{STEP_PRIORITIZE}_{SCRIPT_NAME}_{TIMESTAMP}.csv"

# --- Define Identifier Columns Globally ---
IDENTIFIER_COLS = ['bukrs', 'belnr', 'gjahr', 'buzei']

# --- Helper Functions ---
def print_separator(title=""): print("\n" + "="*30 + f" {title} " + "="*30)
def safe_to_string(series):
    if series is None: return None
    return series.astype(str)
def format_value(value):
    if pd.isna(value): return "N/A"
    if isinstance(value, float) and (abs(value) < 0.01 and value != 0): return f"{value:.2e}"
    if isinstance(value, (int, float)): return f"{value:,.0f}"
    return str(value)

# --- Function to Generate Context ---
def generate_anomaly_context(row):
    """Generates a textual context string based on anomaly flags."""
    context = []
    # Model Consensus
    if row['Model_Anomaly_Count'] == 3:
        context.append("Flagged by ALL models (IF, LOF, AE).")
    elif row['Model_Anomaly_Count'] == 2:
        models = []
        if row.get('IF_Label', 1) == -1: models.append("IF")
        if row.get('LOF_Label', 1) == -1: models.append("LOF")
        if row.get('AE_Label', 1) == -1: models.append("AE")
        context.append(f"Flagged by 2 models ({', '.join(models)}).")
    elif row['Model_Anomaly_Count'] == 1:
        models = []
        if row.get('IF_Label', 1) == -1: models.append("IF")
        if row.get('LOF_Label', 1) == -1: models.append("LOF")
        if row.get('AE_Label', 1) == -1: models.append("AE")
        context.append(f"Flagged by 1 model ({', '.join(models)}).")

    # High-Risk Flags Analysis
    hrf_triggered = []
    if row.get('HRF_IsHighValue', False): hrf_triggered.append("High Value")
    if row.get('HRF_IsHighUserDev', False): hrf_triggered.append("High User Deviation")
    if row.get('HRF_IsHighAcctDev', False): hrf_triggered.append("High Account Deviation")
    if row.get('HRF_IsWeekend', False): hrf_triggered.append("Weekend Posting")
    if row.get('HRF_IsOutsideBusinessHours', False): hrf_triggered.append("Off-Hours Posting")
    if row.get('HRF_IsRareTCodeForUser', False): hrf_triggered.append("Rare User/TCode Combo")
    if row.get('HRF_IsLowValue', False): hrf_triggered.append("Low Value")
    if row.get('HRF_IsMissingCostCenter', False): hrf_triggered.append("Missing Cost Center (Expense?)")

    if hrf_triggered:
        context.append(f"Key Risk Flags: {'; '.join(hrf_triggered)}.")
    elif row['Model_Anomaly_Count'] > 0: # Flagged but no specific HRF triggered
         context.append("Flagged by model(s) but no specific high-risk feature threshold met.")

    # Add TCode/User/Account context
    context.append(f"Process context: TCode={row.get('tcode', 'N/A')}, User={row.get('usnam_bkpf', 'N/A')}, Account={row.get('racct', 'N/A')}, DocType={row.get('blart', 'N/A')}.")

    return " | ".join(context)


# --- 1. Load Required Data ---
# ... (Loading logic remains the same) ...
print_separator(f"[Phase {PHASE_NUMBER} Step {STEP_PRIORITIZE}] Loading Data")
df_engineered = None; df_baseline_results = None; df_ae_results = None
try:
    print(f"Loading original engineered features from: {input_engineered_path}"); df_engineered = pd.read_csv(input_engineered_path, low_memory=False); print(f"  Loaded df_engineered: {df_engineered.shape}")
    if 'original_index' not in df_engineered.columns: df_engineered = df_engineered.reset_index().rename(columns={'index':'original_index'})
    print(f"Loading baseline results from: {input_baseline_results_path}"); df_baseline_results = pd.read_csv(input_baseline_results_path, low_memory=False); print(f"  Loaded df_baseline_results: {df_baseline_results.shape}")
    print(f"Loading autoencoder results from: {input_ae_results_path}"); df_ae_results = pd.read_csv(input_ae_results_path, low_memory=False); print(f"  Loaded df_ae_results: {df_ae_results.shape}")
except FileNotFoundError as fnf_error: print(f"CRITICAL ERROR: Input file not found: {fnf_error}. Check paths/timestamps."); exit()
except Exception as e: print(f"CRITICAL ERROR loading data: {e}"); traceback.print_exc(); exit()


# --- 2. Merge All Results ---
# ... (Merging logic remains the same) ...
print_separator(f"[Phase {PHASE_NUMBER} Step {STEP_PRIORITIZE}] Merging All Results")
merge_col = 'original_index'
if merge_col not in df_baseline_results.columns or merge_col not in df_ae_results.columns or merge_col not in df_engineered.columns: print(f"CRITICAL ERROR: Merge column '{merge_col}' missing. Cannot merge."); exit()
baseline_cols_to_merge = [merge_col, 'IF_Label', 'IF_Score', 'LOF_Label', 'LOF_Score']; baseline_cols_to_merge = [c for c in baseline_cols_to_merge if c in df_baseline_results.columns]
ae_cols_to_merge = [merge_col, 'AE_Label', 'AE_MSE_Error']; ae_cols_to_merge = [c for c in ae_cols_to_merge if c in df_ae_results.columns]
df_eval_all = pd.merge(df_engineered, df_baseline_results[baseline_cols_to_merge], on=merge_col, how='left')
df_eval_all = pd.merge(df_eval_all, df_ae_results[ae_cols_to_merge], on=merge_col, how='left')
print(f"Final Evaluation DataFrame shape: {df_eval_all.shape}")
label_cols = ['IF_Label', 'LOF_Label', 'AE_Label']; missing_labels = False
for col in label_cols:
    if col not in df_eval_all.columns: print(f"Warning: Label column '{col}' not found."); missing_labels=True
    elif df_eval_all[col].isnull().any(): print(f"Warning: NaNs found in '{col}'."); missing_labels=True
for col in label_cols:
     if col in df_eval_all.columns: df_eval_all[col] = df_eval_all[col].fillna(1).astype(int)


# --- 3. Define High-Risk Feature Flags ---
# ... (Flag definition logic remains the same) ...
print_separator(f"[Phase {PHASE_NUMBER} Step {STEP_PRIORITIZE}] Defining High-Risk Flags")
high_risk_flags = []
try:
    user_dev_thresh = df_eval_all['FE_AmountDeviationFromUserMean'].abs().quantile(USER_DEV_ABS_PERC / 100.0)
    acct_dev_thresh = df_eval_all['FE_AmountDeviationFromAccountMean'].abs().quantile(ACCT_DEV_ABS_PERC / 100.0)
    high_val_thresh = df_eval_all['FE_AbsoluteAmount'].quantile(HIGH_VALUE_ABS_PERC / 100.0)
    print(f"  User Deviation Threshold: {user_dev_thresh:.4f}"); print(f"  Acct Deviation Threshold: {acct_dev_thresh:.4f}"); print(f"  High Value Threshold: {high_val_thresh:,.2f}"); print(f"  Low Value Threshold: {LOW_VALUE_ABS_THRESHOLD:,.2f}")
    if 'FE_AmountDeviationFromUserMean' in df_eval_all.columns: df_eval_all['HRF_IsHighUserDev'] = (df_eval_all['FE_AmountDeviationFromUserMean'].abs() > user_dev_thresh)
    if 'FE_AmountDeviationFromAccountMean' in df_eval_all.columns: df_eval_all['HRF_IsHighAcctDev'] = (df_eval_all['FE_AmountDeviationFromAccountMean'].abs() > acct_dev_thresh)
    if 'FE_AbsoluteAmount' in df_eval_all.columns: df_eval_all['HRF_IsHighValue'] = (df_eval_all['FE_AbsoluteAmount'] > high_val_thresh)
    if 'FE_AbsoluteAmount' in df_eval_all.columns: df_eval_all['HRF_IsLowValue'] = (df_eval_all['FE_AbsoluteAmount'] < LOW_VALUE_ABS_THRESHOLD)
    rename_dict = {'FE_IsWeekend': 'HRF_IsWeekend', 'FE_IsOutsideBusinessHours': 'HRF_IsOutsideBusinessHours', 'FE_IsRareTCodeForUser': 'HRF_IsRareTCodeForUser', 'FE_IsMissingCostCenterForExpense': 'HRF_IsMissingCostCenter'}
    cols_to_rename = {k: v for k, v in rename_dict.items() if k in df_eval_all.columns}
    df_eval_all.rename(columns=cols_to_rename, inplace=True)
    high_risk_flags = [col for col in df_eval_all.columns if col.startswith('HRF_')]
    print(f"Created High-Risk Flags: {high_risk_flags}")
except KeyError as e: print(f"ERROR: Missing feature column needed for flags: {e}."); high_risk_flags = []
except Exception as e: print(f"ERROR during flag creation: {e}"); traceback.print_exc(); high_risk_flags = []

# --- 4. Calculate Model Consensus & Score Percentiles ---
# ... (Consensus/Score calculation remains the same) ...
print_separator(f"[Phase {PHASE_NUMBER} Step {STEP_PRIORITIZE}] Calculating Consensus and Scores")
df_eval_all['Model_Anomaly_Count'] = df_eval_all[label_cols].apply(lambda row: sum(row[col] == -1 for col in label_cols if col in row), axis=1) # More robust sum
print("Model Consensus Counts (Distribution):"); print(df_eval_all['Model_Anomaly_Count'].value_counts())
if 'IF_Score' in df_eval_all.columns: df_eval_all['IF_Score_Percentile'] = df_eval_all['IF_Score'].rank(pct=True) * 100
if 'LOF_Score' in df_eval_all.columns: df_eval_all['LOF_Score_Percentile'] = df_eval_all['LOF_Score'].rank(pct=True) * 100
if 'AE_MSE_Error' in df_eval_all.columns: df_eval_all['AE_MSE_Percentile'] = df_eval_all['AE_MSE_Error'].rank(pct=True) * 100

# --- 5. Apply Prioritization Logic ---
# ... (Tier logic remains the same) ...
print_separator(f"[Phase {PHASE_NUMBER} Step {STEP_PRIORITIZE}] Applying Prioritization Tiers")
if high_risk_flags: df_eval_all['HRF_Count'] = df_eval_all[high_risk_flags].sum(axis=1)
else: df_eval_all['HRF_Count'] = 0; print("Warning: High-risk flag count defaulted to 0.")
conditions = [
    ((df_eval_all['Model_Anomaly_Count'] >= 2) & (df_eval_all['HRF_Count'] >= 2)) | (df_eval_all['Model_Anomaly_Count'] >= 3) | (((df_eval_all.get('IF_Score_Percentile', 101) <= IF_SCORE_PERC_HIGH) | (df_eval_all.get('LOF_Score_Percentile', 101) <= LOF_SCORE_PERC_HIGH) | (df_eval_all.get('AE_MSE_Percentile', -1) >= AE_MSE_PERC_HIGH)) & (df_eval_all['HRF_Count'] >= 1)),
    (df_eval_all['Model_Anomaly_Count'] >= 2) | ((df_eval_all['Model_Anomaly_Count'] == 1) & (df_eval_all['HRF_Count'] >= 2)) | (((df_eval_all.get('IF_Score_Percentile', 101) <= IF_SCORE_PERC_HIGH) | (df_eval_all.get('LOF_Score_Percentile', 101) <= LOF_SCORE_PERC_HIGH) | (df_eval_all.get('AE_MSE_Percentile', -1) >= AE_MSE_PERC_HIGH))),
    ((df_eval_all['Model_Anomaly_Count'] == 1) & (df_eval_all['HRF_Count'] == 1)) ]
choices = [1, 2, 3]; default_priority = 4
df_eval_all['Priority_Tier'] = np.select(conditions, choices, default=default_priority)
df_eval_all.loc[df_eval_all['Model_Anomaly_Count'] == 0, 'Priority_Tier'] = np.nan
print("Priority Tier Distribution:"); print(df_eval_all['Priority_Tier'].value_counts(dropna=False))

# --- 6. Filter, Sort, and Prepare Output List ---
print_separator(f"[Phase {PHASE_NUMBER} Step {STEP_PRIORITIZE}] Preparing Prioritized Anomaly List")
df_prioritized = df_eval_all[df_eval_all['Model_Anomaly_Count'] > 0].copy()
sort_columns = ['Priority_Tier', 'Model_Anomaly_Count']; ascending_order = [True, False]
if 'AE_MSE_Error' in df_prioritized.columns: sort_columns.append('AE_MSE_Error'); ascending_order.append(False)
if 'IF_Score' in df_prioritized.columns: sort_columns.append('IF_Score'); ascending_order.append(True)
if 'LOF_Score' in df_prioritized.columns: sort_columns.append('LOF_Score'); ascending_order.append(True)
df_prioritized.sort_values(by=sort_columns, ascending=ascending_order, inplace=True)
df_output_list = df_prioritized.head(NUM_ANOMALIES_TO_OUTPUT).copy() # Explicit copy

# --- 7. Generate Anomaly Context ---
print_separator(f"[Phase {PHASE_NUMBER} Step {STEP_PRIORITIZE}] Generating Review Context")
if not df_output_list.empty:
    # Apply the context function row by row
    df_output_list['Review_Focus'] = df_output_list.apply(generate_anomaly_context, axis=1)
    print("Generated 'Review_Focus' context for top anomalies.")
else:
    print("No anomalies found to generate context for.")

# --- 8. Save Prioritized List with Context --- (Renumbered)
print_separator(f"[Phase {PHASE_NUMBER} Step {STEP_PRIORITIZE}] Saving Prioritized Anomaly List")
if not df_output_list.empty:
    # Select final output columns, including the new context column
    output_cols = IDENTIFIER_COLS + \
                  ['Priority_Tier', 'Model_Anomaly_Count'] + \
                  [lbl for lbl in label_cols if lbl in df_output_list.columns] + \
                  [s + '_Score' for s in ['IF', 'LOF'] if s + '_Score' in df_output_list.columns] + \
                  (['AE_MSE_Error'] if 'AE_MSE_Error' in df_output_list.columns else []) + \
                  high_risk_flags + \
                  ['blart', 'tcode', 'usnam_bkpf', 'racct', 'hsl', 'budat_bkpf'] + \
                  ['Review_Focus'] # Add the new column

    output_cols = [c for c in output_cols if c in df_output_list.columns] # Ensure existence
    df_output_final = df_output_list[output_cols] # Create final df with selected columns

    print(f"\nTop {NUM_ANOMALIES_TO_OUTPUT} Prioritized Anomalies with Context (Sample):")
    # Adjust display options for better readability
    pd.set_option('display.max_colwidth', 150) # Show more text in context column
    pd.set_option('display.width', 1000)
    print(df_output_final.head(10).to_string()) # Print sample

    # Save the prioritized list
    prioritized_list_path = os.path.join(output_directory, prioritized_list_filename)
    try:
        df_output_final.to_csv(prioritized_list_path, index=False, encoding='utf-8', float_format='%.4f')
        print(f"\nSuccessfully saved prioritized anomaly list ({len(df_output_final)} rows) to: {prioritized_list_path}")
    except Exception as e: print(f"ERROR: Failed to save prioritized list: {e}"); traceback.print_exc()
else:
    print("No anomalies were selected for output.")


print(f"\n--- Script {SCRIPT_NAME}.py ({TIMESTAMP}) Complete ---")
print("Outputs generated:")
if not df_output_list.empty: print(f" - {prioritized_list_filename}")
else: print(" - No prioritized anomaly file generated (no anomalies met criteria).")